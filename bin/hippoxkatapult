#!/usr/bin/env python

"""

Driver script for the hippoxkatapult package

Given a MeerKAT captureBlockId:
    - fetch dataset from archive (mocked up at the moment)
    - unpack it set-it up in a staging directory
    - set-up an oxkat run
    - run oxkat pipeline stages, checking output after each stage
    - generate catalogs with PyBDSF
    - tidy up (keep images, catalogs, possibly MS for re-imaging)

"""

import os
import sys
import argparse
import subprocess
import glob
from hippoxkatapult import startup, archive, jobs

#------------------------------------------------------------------------------------------------------------
def makeParser():
    parser=argparse.ArgumentParser("hippoxkatapult")
    parser.add_argument("task", help="Task to run - either 'stage' (retrieve data from the archive, unpack\
                        it, and prepare it for processing), or 'process' (everything else - calibration,\
                        imaging etc.).")
    parser.add_argument("captureBlockId", help="MeerKAT observation to fetch and process\
                        (identified by captureBlockId in the MeerKAT archive).")
    return parser

#------------------------------------------------------------------------------------------------------------
if __name__ == '__main__':

    parser=makeParser()
    args=parser.parse_args()
    captureBlockId=args.captureBlockId

    stagingDir=startup.config["stagingDir"]
    MSPath=stagingDir+os.path.sep+captureBlockId+"_sdp_l0.ms"
    topDir=os.getcwd()

    if args.task == 'stage':
        archive.fetchFromArchive(captureBlockId)
        if os.path.exists(MSPath) == False:
            tgzPath=stagingDir+os.path.sep+"%s_sdp_l0.ms.tar.gz" % (captureBlockId)
            if archive.checkUnpacking(captureBlockId) == False:
                os.system("screen -S unpack-%s -d -m tar -zxvf %s -C %s/" % (captureBlockId, tgzPath, stagingDir))
                print("unpacking %s - this will take a while" % (tgzPath))
            else:
                print("already unpacking %s" % (tgzPath))
        else:
            print("measurement set %s is already staged" % (MSPath))
        sys.exit()

    elif args.task == 'process':

        # Move the unpacked MS into the staging dir (almost instant)
        if os.path.exists(MSPath) == False:
            for p in os.walk(stagingDir+os.path.sep+"scratch"):
                if p[1][0] == os.path.split(MSPath)[-1]:
                    break
            mvCmd="mv %s/%s %s/" % (p[0], p[1][0], stagingDir)
            os.system(mvCmd)

        # Setup in processing dir
        MSProcessDir=startup.config['processingDir']+os.path.sep+captureBlockId
        if os.path.exists(MSProcessDir) == True:
            raise Exception("Processing directory %s exists and is not empty - remove it and re-run, if you're sure you don't need its contents." % (MSProcessDir))
        os.makedirs(MSProcessDir)
        os.chdir(MSProcessDir)
        os.system("ln -s %s" % (os.path.abspath(MSPath)))
        oxdirs=['setups', 'tools', 'oxkat']
        for oxdir in oxdirs:
            os.system("ln -s %s" % (startup.config['oxkatDir']+os.path.sep+oxdir))

        # Generate the oxkat job scripts then spin through + submit them ourselves
        # 1GC
        os.system("python setups/1GC.py hippo")
        sbatchCmds=[]
        dependent=[]
        with open("submit_1GC_jobs.sh") as inFile:
            lines=inFile.readlines()
            for line in lines:
                if line.find("sbatch") != -1:
                    sbatchCmd=line[line.find("sbatch") :].split(" |")[0]
                    if sbatchCmd.find("-d afterok:") != -1:
                        sbatchCmd=sbatchCmd.split("}")[-1].strip()
                        dependent.append(True)
                    else:
                        sbatchCmd=sbatchCmd.split("sbatch")[-1].strip()
                        dependent.append(False)
                    sbatchCmds.append(sbatchCmd)
        jobIDs=[]
        for cmd, dep in zip(sbatchCmds, dependent):
            if dep == False:
                dependentJobIDs=None
            else:
                dependentJobIDs=jobIDs
            jobName=os.path.split(cmd)[-1]
            jobID=jobs.submitJob(cmd, jobName, dependentJobIDs = dependentJobIDs, cmdIsBatchScript = True)
            jobIDs.append(jobID)

        # Run the FLAG and 2GC setup scripts as a job, then chain them together
        cmd="python setups/FLAG.py hippo"
        jobID=jobs.submitJob(cmd, "SETUP_FLAG_JOBS", dependentJobIDs = jobIDs)
        jobIDs.append(jobID)
        cmd="python setups/2GC.py hippo"
        jobID=jobs.submitJob(cmd, "SETUP_2GC_JOBS", dependentJobIDs = jobIDs)
        jobIDs.append(jobID)
        print("check")
        cmd="hippoxkatapult_chain %s submit_flag_jobs.sh submit_2GC_jobs.sh" % (jobIDs[-1])
        jobID=jobs.submitJob(cmd, "CHAIN_FLAG+2GC_JOBS", dependentJobIDs = jobIDs)
        print("All jobs submitted")

    elif args.task == 'analyse':

        # Setup in processing dir
        MSProcessDir=startup.config['processingDir']+os.path.sep+captureBlockId
        if os.path.exists(MSProcessDir) == False:
            raise Exception("Processing directory %s does not exist - you need to process the data before the analyse task will run." % (MSProcessDir))
        os.chdir(MSProcessDir)
        os.system("ln -s %s" % (startup.config["catalogScriptsDir"]+os.path.sep+"sourcefinding.py"))
        os.system("ln -s %s" % (startup.config["catalogScriptsDir"]+os.path.sep+"catalog_matching.py"))
        os.system("ln -s %s" % (startup.config["catalogScriptsDir"]+os.path.sep+"parsets"))

        # Source finding is fairly lightweight so we put everything in one job script
        # We will have issues with needing to see the internet to fetch cross match catalogs though
        # So we will need to cache NVSS catalogs for a given direction when doing 'stage'
        imgPaths=glob.glob("IMAGES/*datamask-MFS-image.fits")
        for i in imgPaths:
            if i.find("pbcorr_trim") == -1:
                imgPath=os.path.abspath(i)
        cmd="mkat_primary_beam_correct %s -T" % (imgPath)

        imgDir, imgFileName=os.path.split(imgPath)
        pbcorrImgPath=imgDir+os.path.sep+"pbcorr_trim_"+imgFileName
        cmd=cmd+"\npython sourcefinding.py c %s -o fits --survey MSS" % (pbcorrImgPath)

        catPath=imgDir+os.path.sep+"pbcorr_trim_"+imgFileName.split(".ms_")[0]+"_pybdsf"+os.path.sep+\
                "pbcorr_trim_"+imgFileName.split(".ms_")[0]+"_bdsfcat.fits"
        cmd=cmd+"\npython catalog_matching.py %s NVSS --astro --flux" % (catPath)

        jobID=jobs.submitJob(cmd, 'source-finding', dependentJobIDs = None, nodes = 1, tasks = 1, cpusPerTask = 20, mem = 8000,
                             time = "02:00:00", cmdIsBatchScript = False)
        print("Submitted source finding and analysis job")



